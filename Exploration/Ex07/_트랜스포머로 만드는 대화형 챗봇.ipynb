{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "427dcc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e1d9e9",
   "metadata": {},
   "source": [
    "## 데이터 수집하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6b4e868",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_file_path = './ChatbotData .csv'\n",
    "transformer_data = pd.read_csv('./ChatbotData .csv') ## 알보고니 확장자명 쓰기전에 space..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abc3d143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a780a1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11823 entries, 0 to 11822\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Q       11823 non-null  object\n",
      " 1   A       11823 non-null  object\n",
      " 2   label   11823 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 277.2+ KB\n"
     ]
    }
   ],
   "source": [
    "transformer_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caf21644",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_data['length'] = transformer_data['Q'].apply(lambda x: len(x.split()))  # Q열의 문장 길이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce13d91f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 길이 분포 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(transformer_data['length'], bins=50, alpha=0.7, color='blue')\n",
    "plt.title('Distribution of Sentence Lengths')\n",
    "plt.xlabel('Length of Sentences')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "584590d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_data['length'] = transformer_data['A'].apply(lambda x: len(x.split()))  # A열의 문장 길이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54014a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 길이 분포 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(transformer_data['length'], bins=50, alpha=0.7, color='blue')\n",
    "plt.title('Distribution of Sentence Lengths')\n",
    "plt.xlabel('Length of Sentences')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbc3a824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 11823\n"
     ]
    }
   ],
   "source": [
    "num_samples = transformer_data.shape[0]  # 또는 len(transformer_data)\n",
    "print(f'Number of samples: {num_samples}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9d0199",
   "metadata": {},
   "source": [
    "## 데이터 전처리 하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47809251",
   "metadata": {},
   "source": [
    "##  SubwordTextEncoder 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fb97c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SAMPLES = 11823"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "208bfd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip()\n",
    "    \n",
    "    # 구두점과의 거리를 만듭니다 (예: \"I am a student.\" -> \"I am a student .\")\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    \n",
    "    # 공백이 두 개 이상일 때 하나로 치환\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    \n",
    "    # 한글과 영어, 구두점(. , ? !)을 제외한 모든 문자를 공백으로 대체\n",
    "    sentence = re.sub(r'[^a-zA-Z0-9.,?!가-힣]', ' ', sentence)\n",
    "    \n",
    "    sentence = sentence.strip()\n",
    "    return sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee747ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = transformer_data['Q'].apply(preprocess_sentence).tolist()\n",
    "answers = transformer_data['A'].apply(preprocess_sentence).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fddb872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 후의 22번째 질문 샘플: 가스비 장난 아님\n",
      "전처리 후의 22번째 답변 샘플: 다음 달에는 더 절약해봐요 .\n"
     ]
    }
   ],
   "source": [
    "print('전처리 후의 22번째 질문 샘플: {}'.format(questions[21]))\n",
    "print('전처리 후의 22번째 답변 샘플: {}'.format(answers[21]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89cf7364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문과 답변 데이터셋에 대해서 Vocabulary 생성\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7e42aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19759a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 21번째 질문 샘플: [5758, 610, 2487, 4159]\n",
      "정수 인코딩 후의 21번째 답변 샘플: [2355, 7504, 7, 6268, 97, 1]\n"
     ]
    }
   ],
   "source": [
    "# 임의의 22번째 샘플에 대해서 정수 인코딩 작업을 수행.\n",
    "# 각 토큰을 고유한 정수로 변환\n",
    "print('정수 인코딩 후의 21번째 질문 샘플: {}'.format(tokenizer.encode(questions[21])))\n",
    "print('정수 인코딩 후의 21번째 답변 샘플: {}'.format(tokenizer.encode(answers[21])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2068ef6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = tokenizer.vocab_size + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36c15056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 21번째 질문 샘플: [5758, 610, 2487, 4159]\n",
      "정수 인코딩 후의 21번째 답변 샘플: [2355, 7504, 7, 6268, 97, 1]\n"
     ]
    }
   ],
   "source": [
    "print('정수 인코딩 후의 21번째 질문 샘플: {}'.format(tokenizer.encode(questions[21])))\n",
    "print('정수 인코딩 후의 21번째 답변 샘플: {}'.format(tokenizer.encode(answers[21])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f282cf6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
    "MAX_LENGTH = 10\n",
    "print(MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "705823f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "  \n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "    # 최대 길이 40 이하인 경우에만 데이터셋으로 허용\n",
    "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "      tokenized_inputs.append(sentence1)\n",
    "      tokenized_outputs.append(sentence2)\n",
    "  \n",
    "  # 최대 길이 40으로 모든 데이터셋을 패딩\n",
    "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  \n",
    "  return tokenized_inputs, tokenized_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "330d1211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 8166\n",
      "필터링 후의 질문 샘플 개수: 9105\n",
      "필터링 후의 답변 샘플 개수: 9105\n"
     ]
    }
   ],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa5be0f",
   "metadata": {},
   "source": [
    "## positionalEncoding, Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5013d84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 포지셔널 인코딩 레이어\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, position, d_model):\n",
    "    super(PositionalEncoding, self).__init__()\n",
    "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "  def get_angles(self, position, i, d_model):\n",
    "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "    return position * angles\n",
    "\n",
    "  def positional_encoding(self, position, d_model):\n",
    "    # 각도 배열 생성\n",
    "    angle_rads = self.get_angles(\n",
    "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "        d_model=d_model)\n",
    "\n",
    "    # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "    # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    # sin과 cosine이 교차되도록 재배열\n",
    "    pos_encoding = tf.stack([sines, cosines], axis=0)\n",
    "    pos_encoding = tf.transpose(pos_encoding,[1, 2, 0]) \n",
    "    pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "\n",
    "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "    return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab08bdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
    "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "  # 가중치를 정규화\n",
    "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "  logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "  # 패딩에 마스크 추가\n",
    "  if mask is not None:\n",
    "    logits += (mask * -1e9)\n",
    "\n",
    "  # softmax적용\n",
    "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "  # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "  output = tf.matmul(attention_weights, value)\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be984140",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, inputs):\n",
    "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "        'value'], inputs['mask']\n",
    "    batch_size = tf.shape(query)[0]\n",
    "\n",
    "    # Q, K, V에 각각 Dense를 적용합니다\n",
    "    query = self.query_dense(query)\n",
    "    key = self.key_dense(key)\n",
    "    value = self.value_dense(value)\n",
    "\n",
    "    # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
    "    query = self.split_heads(query,batch_size)\n",
    "    key = self.split_heads(key, batch_size)\n",
    "    value = self.split_heads(value, batch_size)\n",
    "\n",
    "    # 스케일드 닷 프로덕트 어텐션 함수\n",
    "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "    # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "    # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "    outputs = self.dense(concat_attention)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fcad0fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "  # (batch_size, 1, 1, sequence length)\n",
    "  return mask[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f3ff140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "  seq_len = tf.shape(x)[1]\n",
    "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "  padding_mask = create_padding_mask(x)\n",
    "  return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7cc82d",
   "metadata": {},
   "source": [
    "## 모델 구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d3ad1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "  attention = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eee2ae1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  # num_layers만큼 쌓아올린 인코더의 층.\n",
    "  for i in range(num_layers):\n",
    "    outputs = encoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name=\"encoder_layer_{}\".format(i),\n",
    "    )([outputs, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3b54ee81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention1 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': look_ahead_mask\n",
    "      })\n",
    "\n",
    "  # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention1 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "  attention2 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "          'query': attention1,\n",
    "          'key': enc_outputs,\n",
    "          'value': enc_outputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "  # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "  attention2 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "  # 세 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c5cfd72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "  # 패딩 마스크\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "  \n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  for i in range(num_layers):\n",
    "    outputs = decoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name='decoder_layer_{}'.format(i),\n",
    "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2720c7",
   "metadata": {},
   "source": [
    "## 교사 강요(Teacher Forcing) 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "957627c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
    "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f972b56",
   "metadata": {},
   "source": [
    "##  모델 정의 및 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "df45a213",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "  # 인코더에서 패딩을 위한 마스크\n",
    "  enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "\n",
    "  # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "  # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "  look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask,\n",
    "      output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "  # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "  # 디코더에서 패딩을 위한 마스크\n",
    "  dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "\n",
    "  # 인코더\n",
    "  enc_outputs = encoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "  # 디코더\n",
    "  dec_outputs = decoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "  # 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "737371aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 512)    23095296    inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 512)    29405184    dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8166)   4189158     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 56,689,638\n",
      "Trainable params: 56,689,638\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "## 하이퍼파라미터\n",
    "NUM_LAYERS = 6 # 인코더와 디코더의 층의 개수 , layer 수가 늘어나도 residual에서 역전파가 뛰어넘음 -> 늘린다고 과적합은 발생안함 \n",
    "D_MODEL = 512 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수\n",
    "UNITS = 2048 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0fb561ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  \n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "  loss = tf.multiply(loss, mask)\n",
    "\n",
    "  return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "06659637",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8a8b9404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "61413298",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "66589783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "143/143 [==============================] - 32s 99ms/step - loss: 5.0955 - accuracy: 0.0972\n",
      "Epoch 2/100\n",
      "143/143 [==============================] - 14s 98ms/step - loss: 4.0672 - accuracy: 0.2099\n",
      "Epoch 3/100\n",
      "143/143 [==============================] - 14s 99ms/step - loss: 3.6158 - accuracy: 0.2152\n",
      "Epoch 4/100\n",
      "143/143 [==============================] - 14s 99ms/step - loss: 3.4229 - accuracy: 0.2222\n",
      "Epoch 5/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 3.2985 - accuracy: 0.2294\n",
      "Epoch 6/100\n",
      "143/143 [==============================] - 14s 101ms/step - loss: 3.1863 - accuracy: 0.2359\n",
      "Epoch 7/100\n",
      "143/143 [==============================] - 14s 101ms/step - loss: 3.0665 - accuracy: 0.2430\n",
      "Epoch 8/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 2.9216 - accuracy: 0.2517\n",
      "Epoch 9/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 2.7498 - accuracy: 0.2657\n",
      "Epoch 10/100\n",
      "143/143 [==============================] - 14s 101ms/step - loss: 2.5650 - accuracy: 0.2820\n",
      "Epoch 11/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 2.3579 - accuracy: 0.3029\n",
      "Epoch 12/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 2.1484 - accuracy: 0.3275\n",
      "Epoch 13/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 1.9451 - accuracy: 0.3537\n",
      "Epoch 14/100\n",
      "143/143 [==============================] - 14s 99ms/step - loss: 1.7502 - accuracy: 0.3797\n",
      "Epoch 15/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 1.5796 - accuracy: 0.4035\n",
      "Epoch 16/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 1.4355 - accuracy: 0.4240\n",
      "Epoch 17/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 1.3202 - accuracy: 0.4391\n",
      "Epoch 18/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 1.2309 - accuracy: 0.4502\n",
      "Epoch 19/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 1.1657 - accuracy: 0.4578\n",
      "Epoch 20/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 1.1188 - accuracy: 0.4643\n",
      "Epoch 21/100\n",
      "143/143 [==============================] - 14s 101ms/step - loss: 1.0843 - accuracy: 0.4689\n",
      "Epoch 22/100\n",
      "143/143 [==============================] - 14s 101ms/step - loss: 1.0642 - accuracy: 0.4718\n",
      "Epoch 23/100\n",
      "143/143 [==============================] - 14s 101ms/step - loss: 1.0421 - accuracy: 0.4736\n",
      "Epoch 24/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 1.0308 - accuracy: 0.4756\n",
      "Epoch 25/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 1.0213 - accuracy: 0.4769\n",
      "Epoch 26/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 1.0175 - accuracy: 0.4755\n",
      "Epoch 27/100\n",
      "143/143 [==============================] - 14s 101ms/step - loss: 1.0100 - accuracy: 0.4776\n",
      "Epoch 28/100\n",
      "143/143 [==============================] - 14s 101ms/step - loss: 1.0260 - accuracy: 0.4754\n",
      "Epoch 29/100\n",
      "143/143 [==============================] - 14s 101ms/step - loss: 0.9930 - accuracy: 0.4801\n",
      "Epoch 30/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 0.9778 - accuracy: 0.4813\n",
      "Epoch 31/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 0.9565 - accuracy: 0.4849\n",
      "Epoch 32/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 0.9331 - accuracy: 0.4876\n",
      "Epoch 33/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 0.9180 - accuracy: 0.4900\n",
      "Epoch 34/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 0.9039 - accuracy: 0.4912s - loss: 0.9031 - ac\n",
      "Epoch 35/100\n",
      "143/143 [==============================] - 14s 101ms/step - loss: 0.8869 - accuracy: 0.4946\n",
      "Epoch 36/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 0.8765 - accuracy: 0.4953\n",
      "Epoch 37/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 0.8664 - accuracy: 0.4968\n",
      "Epoch 38/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 0.8493 - accuracy: 0.4994\n",
      "Epoch 39/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 0.8417 - accuracy: 0.5002\n",
      "Epoch 40/100\n",
      "143/143 [==============================] - 14s 101ms/step - loss: 0.8233 - accuracy: 0.5034\n",
      "Epoch 41/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 0.8147 - accuracy: 0.5035\n",
      "Epoch 42/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 0.8033 - accuracy: 0.5046\n",
      "Epoch 43/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 0.7909 - accuracy: 0.5074\n",
      "Epoch 44/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 0.7867 - accuracy: 0.5070\n",
      "Epoch 45/100\n",
      "143/143 [==============================] - 14s 101ms/step - loss: 0.7742 - accuracy: 0.5092\n",
      "Epoch 46/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 0.7688 - accuracy: 0.5092\n",
      "Epoch 47/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 0.7603 - accuracy: 0.5110\n",
      "Epoch 48/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 0.7525 - accuracy: 0.5119\n",
      "Epoch 49/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 0.7501 - accuracy: 0.5130\n",
      "Epoch 50/100\n",
      "143/143 [==============================] - 14s 101ms/step - loss: 0.7377 - accuracy: 0.5137\n",
      "Epoch 51/100\n",
      "143/143 [==============================] - 14s 101ms/step - loss: 0.7329 - accuracy: 0.5139\n",
      "Epoch 52/100\n",
      "143/143 [==============================] - 14s 101ms/step - loss: 0.7236 - accuracy: 0.5154\n",
      "Epoch 53/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 0.7183 - accuracy: 0.5159\n",
      "Epoch 54/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 0.7108 - accuracy: 0.5167\n",
      "Epoch 55/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 0.7000 - accuracy: 0.5182\n",
      "Epoch 56/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 0.6937 - accuracy: 0.5196\n",
      "Epoch 57/100\n",
      "143/143 [==============================] - 14s 101ms/step - loss: 0.6808 - accuracy: 0.5199\n",
      "Epoch 58/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 0.6724 - accuracy: 0.5214\n",
      "Epoch 59/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 0.6585 - accuracy: 0.5229\n",
      "Epoch 60/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 0.6513 - accuracy: 0.5240\n",
      "Epoch 61/100\n",
      "143/143 [==============================] - 14s 101ms/step - loss: 0.6407 - accuracy: 0.5255\n",
      "Epoch 62/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 0.6328 - accuracy: 0.5266\n",
      "Epoch 63/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 0.6230 - accuracy: 0.5279\n",
      "Epoch 64/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 0.6176 - accuracy: 0.5287\n",
      "Epoch 65/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 0.6096 - accuracy: 0.5285\n",
      "Epoch 66/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 0.5984 - accuracy: 0.5301\n",
      "Epoch 67/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 0.5988 - accuracy: 0.5301\n",
      "Epoch 68/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 0.5870 - accuracy: 0.5319\n",
      "Epoch 69/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 0.5778 - accuracy: 0.5332\n",
      "Epoch 70/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 0.5719 - accuracy: 0.5347\n",
      "Epoch 71/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 0.5704 - accuracy: 0.5343\n",
      "Epoch 72/100\n",
      "143/143 [==============================] - 14s 101ms/step - loss: 0.5619 - accuracy: 0.5350s - loss:\n",
      "Epoch 73/100\n",
      "143/143 [==============================] - 14s 101ms/step - loss: 0.5586 - accuracy: 0.5357\n",
      "Epoch 74/100\n",
      "143/143 [==============================] - 14s 101ms/step - loss: 0.5483 - accuracy: 0.5369\n",
      "Epoch 75/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 0.5433 - accuracy: 0.5388\n",
      "Epoch 76/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 0.5409 - accuracy: 0.5381\n",
      "Epoch 77/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 0.5359 - accuracy: 0.5389\n",
      "Epoch 78/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 0.5272 - accuracy: 0.5404\n",
      "Epoch 79/100\n",
      "143/143 [==============================] - 14s 101ms/step - loss: 0.5322 - accuracy: 0.5398\n",
      "Epoch 80/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 0.5197 - accuracy: 0.5420\n",
      "Epoch 81/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 0.5186 - accuracy: 0.5414\n",
      "Epoch 82/100\n",
      "143/143 [==============================] - 14s 101ms/step - loss: 0.5124 - accuracy: 0.5433\n",
      "Epoch 83/100\n",
      "143/143 [==============================] - 14s 101ms/step - loss: 0.5080 - accuracy: 0.5434\n",
      "Epoch 84/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 0.5034 - accuracy: 0.5442\n",
      "Epoch 85/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 0.4979 - accuracy: 0.5443\n",
      "Epoch 86/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 0.4944 - accuracy: 0.5449\n",
      "Epoch 87/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 0.4920 - accuracy: 0.5451\n",
      "Epoch 88/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 0.4857 - accuracy: 0.5466\n",
      "Epoch 89/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 0.4819 - accuracy: 0.5471\n",
      "Epoch 90/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 0.4820 - accuracy: 0.5467\n",
      "Epoch 91/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 0.4770 - accuracy: 0.5485\n",
      "Epoch 92/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 0.4726 - accuracy: 0.5483\n",
      "Epoch 93/100\n",
      "143/143 [==============================] - 14s 101ms/step - loss: 0.4680 - accuracy: 0.5489\n",
      "Epoch 94/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 0.4660 - accuracy: 0.5497\n",
      "Epoch 95/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 0.4622 - accuracy: 0.5506\n",
      "Epoch 96/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 0.4632 - accuracy: 0.5500\n",
      "Epoch 97/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 0.4577 - accuracy: 0.5514\n",
      "Epoch 98/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 0.4521 - accuracy: 0.5528\n",
      "Epoch 99/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 0.4523 - accuracy: 0.5514\n",
      "Epoch 100/100\n",
      "143/143 [==============================] - 14s 100ms/step - loss: 0.4516 - accuracy: 0.5516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7e9caf62fc10>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b5c404",
   "metadata": {},
   "source": [
    "## 챗봇 테스트하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0ecc4b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_inference(sentence):\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
    "  # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
    "  sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "  # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "  # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
    "  output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  # 디코더의 인퍼런스 단계\n",
    "  for i in range(MAX_LENGTH):\n",
    "    # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "    predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "    predictions = predictions[:, -1:, :]\n",
    "\n",
    "    # 현재 예측한 단어의 정수\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "      break\n",
    "\n",
    "    # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "    # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "    output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output_sequence, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "39593697",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(sentence):\n",
    "  # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "  prediction = decoder_inference(sentence)\n",
    "\n",
    "  # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "  print('입력 : {}'.format(sentence))\n",
    "  print('출력 : {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4f5e1ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 안녕\n",
      "출력 : 잘 찾아보세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'잘 찾아보세요 .'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## drop out 0.5, max_length = 10\n",
    "sentence_generation('안녕')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0666bdc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 오늘 날씨 어때\n",
      "출력 : 잘 찾아보세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'잘 찾아보세요 .'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('오늘 날씨 어때')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "95050397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 오늘 뭐 먹어?\n",
      "출력 : 잘 찾아보세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'잘 찾아보세요 .'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('오늘 뭐 먹어?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ee88a3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 안녕\n",
      "출력 : 안녕하세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'안녕하세요 .'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## dropout 0.1, max_length = 10\n",
    "sentence_generation('안녕')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5c506e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 오늘 날씨 어때\n",
      "출력 : 칭찬이네요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'칭찬이네요 .'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('오늘 날씨 어때')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ee45467c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 오늘 뭐해?\n",
      "출력 : 저랑 같이 놀아요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'저랑 같이 놀아요 .'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('오늘 뭐해?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3e91018b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 머리 아파\n",
      "출력 : 시간이 흐르면서 무덤덤해지는 거죠 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'시간이 흐르면서 무덤덤해지는 거죠 .'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('머리 아파')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "87cab837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 물건이 망가졌어\n",
      "출력 : 마음에서도 지워주세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'마음에서도 지워주세요 .'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('물건이 망가졌어')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd688b9",
   "metadata": {},
   "source": [
    "## 회고\n",
    "이거 뭐 파라미터만 바꾸면 성능이 바뀌는거 같은데 어떻게 바꿔야 할지 모르겠다. length가 10근처에서 분포가 많이 되어서 10으로 잡아가지고 긴 텍스트를 인식을 못한건지... 잘 모르겠다... \n",
    "dropout을  0.5로 규제를 과하게 잡아서 이상한 답변이 계속 똑같이 나온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baea77c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
